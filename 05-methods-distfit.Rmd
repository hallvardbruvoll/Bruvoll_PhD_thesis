# Methods: Distribution fitting {#methods-distfit}

## Modelling heavy-tailed distributions

```{r 05-libraries, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
```

In this chapter I go into some more detail around the methods used in Chapter \@ref(results-distfit), and the reasoning underlying my choices of methods. As mentioned earlier (Sections \@ref(research-question-and-objectives) and \@ref(power-law)), I consider power-law distributions as a statistical signature of hierarchical structures, and wish to test whether such structures may be reasonably shown to exist among houses in European Neolithic villages, or if house sizes in these contexts are better explained by other non-hierarchical models. Results from these analyses add to current debates surrounding the development of social and political organisation in the Neolithic, and to the question of the emergence of stratified societies more broadly. Furthermore, and as also mentioned in Section \@ref(power-law), the methodological procedure leading to claims of power-law distributed data is not entirely straightforward, and is an issue that has undergone important developments in recent years, often leading to refutations of earlier claims. It is therefore critical to be explicit as to the methods being applied in studies like this one, and not simply report results obtained in some unspecified way through obscurely documented software. In the following I will present #FILL IN AFTERWARDS#. Due to limited space and for simplicity, I will concentrate on the choices of methods and procedure, and not on the under-the-hood functioning of different statistical tools like maximum likelihood estimation and calculation of the Akaike information criterion. For more details on these there is a number of good introductory volumes, some of which -- like @shennan2008 and @baxter2003 -- are also specifically aimed at archaeologists.

The standard method for fitting power-law models to empirical data throughout the 20^th^ century was through least squares linear regression on log-transformed x and y values [e.g. @harrison1981; @mitzenmacher2004], the same way exponential and log-normal models could be fit more easily to data by log-transforming x values. Conscious about the still frequent lack of statistical training among archaeologists, @brown2005 and @brown2010 presented the log-linear regression method as sufficient because of its simplicity of application compared to more sophisticated methods. @brown2010 furthermore provided a detailed discussion around how to plot the data in order to obtain the most accurate parameter estimates. The central problem with fitting power-law models to data, is that power-law distributions characteristically have an overwhelmingly large proportion of the data at lower values, while the scarce high values are typically several orders of magnitude higher. Density plots of empirical data (with the PDF on the y axis) require binning, so that the plotted data points in reality correspond to bar heights in a histogram. The applied bin width will furthermore have a heavy influence on the appearance of the plot, where small bin widths are best to represent the many low values and large bin widths are best for the few high values. Brown and Liebovitch proposed multi-scale PDFs, combining histograms of different bin widths before performing regression, which they showed give better results on synthetic data [-@brown2010, Chapter 2]. Logarithmic binning -- increasing bin width exponentially so that points appear to be spaced as constant increments on a log-transformed x axis is also a possibility that has been proposed [@newman2005, pp. 325-6]. Plotting the cCDF instead of the PDF has the advantage of avoiding the bin-width issue altogether, since y values then are a function of the rank of each data point. This also allows for using all the data and not reducing it into bins, and is shown on synthetic data to give more accurate $\alpha$ estimates (i.e. absolute slope of cCDF $+ 1$, see Eq. \@ref(eq:zipf-exponent)). However, the inconvenience with fitting the power-law model to the cCDF, as pointed out by @brown2010, is that it does not necessarily form a straight line, but will in particular be curved when $\alpha \leq 1$, making it more difficult to distinguish visually from other heavy-tailed distributions.

From the early 2000s, physicists and mathematicians started to criticise the frequent use of log-linear regression methods for modelling power laws, since they were shown to introduce systematic biases to the parameter estimates no matter the adopted plotting method, and calls for the use of more robust methods like maximum likelihood estimation (MLE) were put forth [e.g. @newman2005, pp. 325-7; @stumpf2012]. A new methodological tool kit was proposed by @clauset2009, which has since seemingly become the new gold standard for fitting heavy-tailed distributions. One of their main critiques of earlier practices, came from the recognition that in nearly all real-world contexts where power laws are claimed to exist, this behaviour only kicks in from some lower threshold or $x_{min}$ in the terminology of @clauset2009. In earlier studies the value of this threshold was simply set by guessing from the looks of the plot and trying to fit a line covering as much as possible of the data. More formally, this also impeded proper normalising of the distribution. The method proposed by @clauset2009 consisted in testing a range of different $x_{min}$ values and picking the one that gave the best MLE fit to the data by minimising the KS or Kolmogorov-Smirnov statistic (the largest observed distance between the model and the data), and was reported to perform very well on synthetic data. Next they tested the plausibility of the power-law model through bootstrapping, i.e. generating a large number of synthetic random data sets with the same estimated parameter values, each time measuring the KS statistic compared to the ideal model. The fraction of runs giving a KS statistic higher than that of the empirical data gives the *p*-value, which they argued should lead to a rejection of the power-law hypothesis when $p < 0.1$. They estimated the number of bootstrapping runs necessary for robust p-values being between 1.000 and 10.000, which for a few data series is not dramatic, but for larger numbers of data series quickly become computationally intensive. But most importantly, they argued that the bulk of previous studies claiming to find power laws in empirical data never actually tested and compared their model with alternative models, which they argued should be done even in convincing cases where a power-law model could not be excluded as a good fit through bootstrapping. The method they proposed for comparison and selection between competing models, was Vuong's log-likelihood pairwise comparison test, though pointing out that any good statistical model selection method could serve this purpose [see @clauset2009, p. 663 for an overview of their "recipe for analysing power-law distributed data"]. These methods were later implemented with functions and documentation in the R package *poweRlaw* [@gillespie2015], which has been used and cited in at least some archaeological studies since [@crabtree2017; @haas2015].

For the present study I have largely chosen to follow the instructions advocated by @clauset2009, but with a few modifications, for reasons that are discussed in more detail below. Early experiments with the *poweRlaw* package indicated that the proposed bootstrapping procedure possibly represented a slight overkill, requiring much computing time with relatively limited gains. Furthermore, the pairwise model comparison using the Vuong's log-likelihood test appeared good but somewhat tedious, requiring a nested algorithm eliminating competing models one by one. Therefore I decided instead to opt for testing all candidate model simultaneously using the Akaike Information Criterion (AIC), or rather the version of it designed to correct for small sample sizes -- the AICc. The AIC score is also calculated from the log-likelihood of each model, and indicates which of the candidates accounts for the given data with the most weight. While not implemented in the *poweRlaw* package, it is a frequently used statistical tool implemented in a number of accessible R packages. Here I used the *AICcmodavg* package [@AICcmodavg-package] because of its useful functions for manually tackling the differences in how base R and *poweRlaw* models are coded. I also tested using the Bayesian Information Criterion (BIC) on the data sets, but quickly came to the conclusion that the AICc was sufficient for the types of models being used here, with maximum two parameters.

## Testing for false positive power-law tails

The difficulty of comparing power-law models with other common candidate models (like log-normal or exponential), is that they, unlike the others, by definition need a specified lower bound above 0, denoted *x~min~*. Comparison of multiple models with AIC scores is only meaningful when done over the same range of data [this also applies to the Vuong's log-likelihood test for pairs of models proposed by @clauset2009]. However, comparing multiple models over the range in a data set which has already been recognised as providing the best possible fit for a power-law model, gives this latter model a potential advantage over the other ones. Log-normal models, for instance, can explain the entire range of a data distribution, where a power law can in most cases only explain the highest values in the distribution tail. The fact that these two model types have frequently and for a long time represented competing explanations for the same empirical data sets, may reflect this apparent incomparability between them [e.g. @bee2011; @gibrat1930; @harrison1981; @mitzenmacher2004; @sheridan2018]. One can suspect then that this procedure of distribution fitting and model selection would favour power-law models unreasonably. At the same time, one of the main findings of the @clauset2009 study, was that power-law behaviour was only confirmed beyond reasonable doubt in one out of 24 empirical data sets which had been reported as power-law distributed in earlier studies, leaving the impression that the methodology would be conservative rather than lenient. In many cases however, the study remained inconclusive, especially regarding comparisons between power-law and log-normal models to empirical data sets (comparisons between power-law and other models were generally more conclusive). The authors admitted "*In general, we find that it is extremely difficult to tell the difference between log-normal and power-law behaviour. Indeed, over realistic ranges of* x *the two distributions are very close, so it appears unlikely that any test would be able to tell them apart unless we had an extremely large data set*" [@clauset2009, p. 689]. Extremely large data sets are of course a luxury that is rarely afforded in archaeology, and if these two models are that close in many situations, one can ask whether picking one over the other really matters in the end. This question is further developed in Chapter \@ref(disc-methods).

The reliability of this methodology can to some extent be assessed using synthetic data. A first question to address is whether sample size affects the selected distribution model for the tail, and if so what size should be considered a minimum for the results to be reliable. In Figure \@ref(fig:05-distfit), using random number generator functions in base R [@R2023] and with the *poweRlaw* package [@gillespie2015], I reproduced Fig. 5a in @clauset2009, namely examples of a power-law, a log-normal and an exponential distribution, with the addition here of a stretched exponential, illustrating how they all can look roughly linear on log-log plots with their survival functions/cCDFs. Using the same parameter values, but with four different sample sizes (10, 100, 1.000 and 10.000) on each model, these test distributions were run through the distribution fitting algorithm described above (Figs. \@ref(fig:05-tails) and \@ref(fig:05-pltails)). The power law was correctly identified no matter the sample size, but for the smallest sample size ($n = 10$) all other distribution types also gave power-law tails. For $n \geq 1000$ all distribution types were correctly identified also in their tails, while for $n = 100$ this was only the case for the stretched exponential and the power law. These results are in agreement with the analysis based on p-values obtained from bootstrapping presented by Clauset et al. [-@clauset2009, p. 676 ff.], but the method opted for here is far less computationally intensive. Selecting the best model alternative directly based on AICc is also a less complex operation compared to the sequence of first bootstrapping and then performing pairwise comparisons of log-likelihood as proposed by @clauset2009. The inconvenience with the method proposed here, is of course that there is no guarantee that any of the models tested for are in reality appropriate -- we only find out *which* one of them is the *most* appropriate. The p-value approach in [@clauset2009] does allow for positively rejecting hypotheses that clearly do not fit the data. However, early experiences (not presented in further detail here) gave the impression that this made little practical difference, at least on the data sets analysed in this thesis. Most sample sizes are in the order of $100$ or lower, in which cases bootstrapping remained inconclusive, while it was still interesting to have an indication of which model that gave the best fit. The results shown in Figure \@ref(fig:05-tails) indicate that for sample sizes below ca. $100$ power-law interpretations should be treated with care, and should not be trusted as $n$ approaches ca. $10$.

However, it must be noted that in order to generate the non-power-law distributions with a defined lower threshold as done here [and in @clauset2009], a much larger number of data points is in reality needed if we also consider those falling below that same threshold. For example, to get $1000$ data points with values above $x = 15$ following the log-normal distribution shown in Figure \@ref(fig:05-distfit), they need to be filtered out from a total distribution almost ten times larger. When considering entire data distributions without lower bounds, as is usually the case e.g. when analysing archaeological house-size distributions, the sample size will potentially also need to be much larger for correct model selection, although exactly *how* much larger should depend on the type of distribution and parameter values of the data. Similarly, when Clauset et al. argued that with the MLE method for estimating $\alpha$ in a power-law model, sample sizes around $n \geq 50$ would usually be enough for the estimates to be within 1% accurate [-@clauset2009, p. 669], sample size is here referring to the number of data points actually being considered when fitting, which is $n > x_{min}$ only. For this number to be $50$ or higher, the total size of the distribution could often need to be $500$ or higher, which is far more than most of the house counts per village in this study. This matter of sample size is a question that is perhaps less relevant to physicists and mathematicians, but that may be of crucial importance to archaeologists who regularly suffer from limited amounts of data.

(ref:05-distfit) Synthetic data series drawn from four different distribution types: exponential ($\lambda=0.125$), log-normal ($\mu=0.3$, $\sigma=2$), power-law ($\alpha=2.5$) and stretched exponential/Weibull ($shape = 0.5$ and $scale = 3$), all with $n=100$ data points and $x_{min}=15$. Plot equivalent to Fig.5a in @clauset2009, with deviations due to random fluctuations only. Scales are logarithmic, and all four series appear as roughly straight lines, though only one is a true power law

```{r 05-distfit, fig.cap="(ref:05-distfit)"}
load("Results/fig05_synthdist.RData")
fig05_synthdist
```

(ref:05-tails) Selected tail models for the same synthetic data sets, each with four sample sizes ($n=10^1, 10^2, 10^3, 10^4$). For each tail model, $x_{min}$ is set at the value which gives the best power-law fit. Point size indicates fraction of data points thus included in the tail model. For power-law distributions, all samples are correctly identified, while this is the case only for large samples ($n>10^2$) of log-normal and exponential samples, smaller samples being interpreted as having power-law or stretched exponential tails

```{r 05-tails, fig.cap="(ref:05-tails)"}
load("Results/fig05_type_tail.RData")
fig05_type_tail
```

(ref:05-pltails) Boxplot of all the synthetic data sets, overlaid (in red) with the data points interpreted as power-law tails. X axis is logarithmic -- however the log-normal distributions do not appear symmetric since they are truncated with a lower threshold. Note that especially for log-normals and power laws, larger samples give longer tails. If the model predicts a probability of having a value of 10.000 or more as only 1 in 10.000 or 0.01%, a sample size of 10.000 will probably allow for one such value

```{r 05-pltails, fig.cap="(ref:05-pltails)"}
load("Results/fig05_synth_pl.RData")
fig05_synth_pl
```

\FloatBarrier

A second question more specifically related to the selection between log-normal and power-law models, is whether certain parameter combinations increase the likelihood of log-normal distributions being incorrectly interpreted as power laws. In his extensive review of power-law generating mechanisms, Newman [-@newman2005, p. 347-8] showed algebraically how log-normal distributions can be mistaken for power laws especially when the range of the data that is being analysed is short, and when the value of $\sigma$ is high. More specifically, since the PDF of a log-normal on log scales is a quadratic function -- i.e. a parabola -- sufficiently smaller sections of this will be nearly indistinguishable from straight lines, and can thus be well modelled as a power law. The curvature of the function is characterised by its quadratic term, which is a fraction with $x$ in the numerator and $\sigma$ in the denominator, written $-\frac{(\ln x)^2}{2\sigma^2}$, essentially causing a flatter curvature with higher values of $\sigma$ since this term then will vary more slowly with $x$ [see Eq. 84 in @newman2005 for more details]. The difficulty of distinguishing the two model types empirically undoubtedly lies in the close relationship between them, both being defined as some enhanced exponential distribution [@mitzenmacher2004]. Figure \@ref(fig:05-synth-ln) shows the cCDF plot of 36 synthetically constructed log-normal distributions, with $\mu$ values ranging from 1 to 6 in integer increments, and $\sigma$ values from 0.5 to 3 in increments of 0.5, each with sample size $n = 1000$ and no truncation (i.e. $x > 0$). When plotted this way (with the survival function of the variable), low $\sigma$ values generate angular curves, while high $\sigma$ values generate more parabolic curves.

(ref:05-synth-ln) cCDF plot of 36 synthetic log-normal distributions with parameter values $1 \leq \mu \leq 6$ and $0.5 \leq \sigma \leq 3$. Each distribution is generated with $n = 1000$ data points, but rendered here as lines for clarity. Scales are logarithmic

```{r 05-synth-ln, fig.cap="(ref:05-synth-ln)"}
load("Results/fig05_synth_ln.RData")
fig05_synth_ln
load("Results/pretest2_summary.RData") 
pretest2_summary <- filter(pretest2_summary, tail == "pl") %>%    
  mutate(ntail_n = ntail/n)
```

Running these distributions through the distribution-fitting and model-selecting algorithm, more than half of them are interpreted with a power-law tail (19 of 36, Figures \@ref(fig:05-ln-tail) and @ref(fig:05-ln-pl). These are seemingly spread throughout the parameter space, with the only clear pattern being that for the highest $\sigma$ values, the power-law tails cover only smaller fractions of the data.

(ref:05-ln-tail) Interpreted tail models of the same log-normal distributions. 19 of 36 distributions have tails that are best modelled as power laws. Symbol size indicates fraction of the data included in the tail, with $x_{min}$ parameter set for best possible power law fit. See text for details

```{r 05-ln-tail, fig.cap="(ref:05-ln-tail)"}
load("Results/fig05_ln_tail.RData")
fig05_ln_tail
```

(ref:05-ln-pl) Boxplot of the same 36 synthetic log-normal distributions, overlaid (in red) with data points included in tails interpreted as power laws. The power-law tails stretch across the log-normal data in a range from `r round(min(pretest2_summary$ntail_n)*100, 3)`% (3 data points out of 1000) to `r round(max(pretest2_summary$ntail_n)*100, 3)`%

```{r 05-ln-pl, fig.cap="(ref:05-ln-pl)"}
load("Results/fig05_ln_pl.RData")
fig05_ln_pl
```

What are we then to conclude from these preliminary tests? Clearly, it is a challenge to confidently distinguish between log-normal and power-law distributed data in the high ends of distributions, as noted in the beginning of this section. If the proposed methodological procedure seemingly serves well to identify power-law distributions when that is what they really are, it also seemingly identify these erroneously in the tails of log-normal distributions half of the time, irrespectively of the log-normal parameter values, and with (for archaeologists) optimistic sample sizes. A more positive way to look at it, is to acknowledge that in truly log-normally distributed data, some definable portion of the upper tail is in many cases indistinguishable from a power law, and actually best modelled as such. There may well be precise mathematical reasons behind this, but further insight to whether such power-law tails are confidently indicative of social hierarchies when observed on material culture proxies such as house sizes, would perhaps require large-scale systematic testing on ethnographically documented cases, which would clearly go beyond the scope of this thesis.

\FloatBarrier

## Methodological procedure

-   Reminder of main goal for this part of the study: identify power-law structures in the house-size distributions of the Linear Pottery and Trypillia samples.

-   Synthetic data genaration:

    -   Why?

        1.  Process: how long/much does it take for a normal distribution to become power-law? And reverse sense? (multiplicative process)

        2.  Temporal resolution issue: does the temporal palimpsest of several phases with e.g. log-normal distributions produce false power-law signals? (additive process)

    -   How?

        -   Random number generation and iterated multiplicative (1.) or additive (2.) sequences, with K-S testing [@gillespie2015] at each stage. Report when the distributions become power laws.

-   Present data set with categories (settlements, quarters/neighbourhoods, time samples for Vr√°ble)

-   Parameter settings: dist. types, xmin, testing the pl hypothesis etc. Minimal house-count cutoff (min. sample size). Isolating top house.

END chapter
