# Methods: Distribution fitting {#methods-distfit}

## Heavy-tailed distributions, testing for power laws

-   Technical characteristics of power laws, @newman2005, do I need more?

-   Old style distribution fitting (which is used in @brown2010 and @brown2005 and check. @mitzenmacher2004, @harrison1981

-   New style presented in @clauset2009, @stumpf2012, implemented in R with the poweRlaw package @gillespie2015, and used in @strawinska-zanko2018 and @crabtree2017.

    -   Finding best x-min value for power-law iteratively with maximum likelihood estimation (the actual fitting) and KS-testing (selecting the best fit).

    -   Comparing this fit with that of other model candidates, setting the same x-min and selecting the best through AICc scores (this deviates from the procedure in @clauset2009 and @gillespie2015, but is commonly done in other contexts when comparing multiple models at once [e.g. @dauphiné2011].

The difficulty of comparing power-law models with other common candidate models (like log-normal or exponential), is that they, unlike the others, by definition need a specified lower bound above 0, denoted *x~min~*. Comparison of multiple models with AIC scores is only meaningful when done over the same range of data [this also applies to the Vuong's log-likelihood test for pairs of models proposed by @clauset2009]. However, comparing multiple models over the range in a data set which has already been recognised as providing the best possible fit for a power-law model, gives this latter model a potential advantage over the other ones. Log-normal models, for instance, can explain the entire range of a data distribution, where a power law can only explain the tail of the highest values. The fact that these two model types have frequently and for a long time represented competing explanations for the same empirical data sets, may reflect this apparent incomparability between them [@mitzenmacher2004; @harrison1981]. One can suspect then that this procedure of distribution fitting and model selection would favour power-law models unreasonably. At the same time, one of the main findings of the @clauset2009 study, was that power-law behaviour was only confirmed beyond reasonable doubt in one out of 24 empirical data sets which had been reported as power-law distributed in earlier studies, leaving the impression that the methodology would be conservative rather than lenient. In many cases however, the study remained inconclusive, especially regarding comparisons between power-law and log-normal models to empirical data sets (comparisons between power-law and other models were generally more conclusive). The authors admitted "*In general, we find that it is extremely difficult to tell the difference between log-normal and power-law behavior. Indeed, over realistic ranges of* x *the two distributions are very close, so it appears unlikely that any test would be able to tell them apart unless we had an extremely large data set*" [@clauset2009, p. 689]. Extremely large data sets are of course a luxury that is rarely afforded in archaeology, and if these two models are that close in many situations, one can ask whether picking one over the other really matters in the end. This question is further developed in Chapter \@ref(disc-methods).

REWRITE: So I decided to do a small pre-analysis, to check if synthetic log-normal distributions get power-law tails with this methodology, and under which circumstances.

First: real vs retained distribution model, with set param values (ln, exp, and pl), and different n.

(ref:05-distfit) Synthetic data series drawn from three different distribution types: exponential ($\lambda=0.125$), power-law ($\alpha=2.5$) and log-normal ($\mu=0.3$, $\sigma=2$), all with $n=100$ data points and $x_{min}=15$. Reproduction of Fig.5a in Clauset et al. (2009), with deviations due to random fluctuations. Scales are logarithmic, and all three series appear as straight lines, though one is a true power law.

```{r 05-distfit, echo=FALSE, fig.cap="(ref:05-distfit)", out.width='80%', fig.asp=.75, fig.align='center'}
load("Results/fig05_synthdist.RData")
fig05_synthdist
```

(ref:next) caption

```{r next, fig.cap="(ref:next)", out.width='80%', fig.asp=.75, fig.align='center'}
load("Results/fig05_type_tail.RData")
fig05_type_tail
```

(ref:next2) caption here

```{r next2, fig.cap="(ref:next2)", out.width='80%', fig.asp=.75, fig.align='center'}
load("Results/fig05_synth_pl.RData")
fig05_synth_pl
```
\FloatBarrier

Second: Ln giving pl tail, set n, different meanlog and sdlog.

## Methodological procedure

-   Reminder of main goal for this part of the study: identify power-law structures in the house-size distributions of the Linear Pottery and Trypillia samples.

-   Synthetic data genaration:

    -   Why?

        1.  Process: how long/much does it take for a normal distribution to become power-law? And reverse sense? (multiplicative process)

        2.  Temporal resolution issue: does the temporal palimpsest of several phases with e.g. log-normal distributions produce false power-law signals? (additive process)

    -   How?

        -   Random number generation and iterated multiplicative (1.) or additive (2.) sequences, with K-S testing [@gillespie2015] at each stage. Report when the distributions become power laws.

-   Present data set with categories (settlements, quarters/neighbourhoods, time samples for Vráble)

-   Parameter settings: dist. types, xmin, testing the pl hypothesis etc. Minimal house-count cutoff (min. sample size). Isolating top house.

## 

END chapter
